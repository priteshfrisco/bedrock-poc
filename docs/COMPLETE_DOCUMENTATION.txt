================================================================================
                    BEDROCK POC - COMPLETE DOCUMENTATION
                         Product Classification System
                            Version 1.0.0 (2025-01-24)
================================================================================

TABLE OF CONTENTS
-----------------
1. SYSTEM OVERVIEW
2. GETTING STARTED
3. FILE STRUCTURE
4. PROMPT MANAGEMENT
5. FILTERING PATTERNS
6. REFERENCE DATA
7. TESTING
8. TROUBLESHOOTING
9. COMMON MODIFICATIONS
10. SUPPORT


================================================================================
1. SYSTEM OVERVIEW
================================================================================

This system classifies Amazon supplement products using:
- AWS Bedrock (or OpenAI GPT-5-mini for testing)
- Two-stage filtering to remove non-supplements
- Keyword-based classification (fast, free)
- LLM-based classification (accurate, costs money)
- Attribute extraction (count, size, unit)

OUTPUT: 15 fields matching R system format
  1. ingredient           (Primary ingredient)
  2. asin                 (RetailerSku)
  3. age                  (Age Group)
  4. count                (Number of units)
  5. unit_of_measurement  (oz, count, etc.)
  6. form                 (Capsule, Tablet, etc.)
  7. category             (Category)
  8. subcategory          (Subcategory)
  9. gender               (Gender)
  10. health_focus        (Health Focus)
  11. title               (Original title)
  12. brand               (Brand)
  13. size                (Amount per unit)
  14. organic             (ORGANIC or NOT ORGANIC)
  15. high_level_category (PRIORITY VMS, NON-PRIORITY VMS, OTC, REMOVE)

BONUS FIELDS:
  - reasoning: Explains classification decision
  - confidence: high/medium/low


================================================================================
2. GETTING STARTED
================================================================================

PREREQUISITES
-------------
- Python 3.8+
- AWS account (for production)
- OpenAI API key (for testing)

INSTALLATION
------------
1. Clone the repository
2. Create virtual environment: python -m venv venv
3. Activate: source venv/bin/activate (Mac/Linux) or venv\Scripts\activate (Windows)
4. Install dependencies: pip install -r requirements.txt
5. Copy .env.example to .env
6. Add your API keys to .env

CONFIGURATION
-------------
Edit .env file:
  ENVIRONMENT=local              # local or aws
  OPENAI_API_KEY=your_key_here   # For testing
  AWS_PROFILE=default            # For production
  AWS_REGION=us-east-1

RUNNING THE SYSTEM
------------------
# Test with 5 products
python test_detailed_output.py

# Test with 10 products
python test_quick_load.py

# Test filtering patterns
python test_filtering_patterns.py

# Test prompts
python test_prompt_changes.py

# Full production run (when ready)
python src/main.py --process-all


================================================================================
3. FILE STRUCTURE
================================================================================

bedrock-poc/
├── src/                           # Source code
│   ├── clients/                   # Storage & tracking
│   │   ├── storage_client.py      # S3/local file operations
│   │   └── file_tracker.py        # DynamoDB/JSON tracking
│   ├── core/                      # Core processing
│   │   ├── preprocessor.py        # Data standardization
│   │   ├── pipeline.py            # Main orchestrator
│   │   └── file_logger.py         # Per-file logging
│   ├── knowledge/                 # Classification logic
│   │   ├── subcategory_filter.py  # Remove non-supplements
│   │   ├── ingredient_classifier.py # Keyword matching
│   │   ├── attribute_extractor.py  # Extract count/size
│   │   ├── classification_validator.py # Validate output
│   │   └── llm_classifier.py      # LLM classification
│   ├── prompts/                   # Prompt management
│   │   └── prompt_builder.py      # Load & build prompts
│   └── main.py                    # Entry point
│
├── prompts/                       # LLM prompt templates
│   └── classification_prompts.json # System & user prompts
│
├── reference_data/                # Configuration files
│   ├── amazon_subcategory_lookup.json  # 409 known categories
│   ├── non_supplement_patterns.json    # Title filtering patterns
│   ├── ingredient_category_lookup.json # Keyword mappings
│   ├── ingredient_health_focus_lookup.json # Health focus fallback
│   ├── valid_categories.json      # All valid categories
│   └── valid_attributes.json      # All valid attributes
│
├── data/                          # Data storage
│   ├── input/                     # Input CSV files
│   ├── output/                    # Final output files
│   ├── logs/                      # Step-wise logs
│   │   └── {file_id}/run_1/       # Per-file, per-run
│   └── audit/                     # Complete audit trail
│       └── {file_id}/run_1/       # Rejection files + manifest
│
├── docs/                          # Documentation
│   └── COMPLETE_DOCUMENTATION.txt # This file
│
└── tests/                         # Test scripts
    ├── test_detailed_output.py
    ├── test_filtering_patterns.py
    ├── test_prompt_changes.py
    └── test_parallel_processing.py


================================================================================
4. PROMPT MANAGEMENT
================================================================================

LOCATION
--------
prompts/classification_prompts.json

FILE STRUCTURE
--------------
{
  "version": "1.0.0",
  "author": "Team Name",
  "last_modified": "2025-01-24",
  "system_message": {
    "role": "system",
    "content": "You are a supplement classification expert..."
  },
  "user_template": {
    "role": "user",
    "content": "Classify these products...\n{categories}\n{products}"
  },
  "few_shot_examples": [...]
}

PLACEHOLDERS
------------
The following are automatically filled from reference data:
  {categories}     - Valid categories and subcategories
  {forms}          - Valid product forms
  {age_groups}     - Valid age groups
  {genders}        - Valid genders
  {health_focuses} - Valid health focuses
  {products}       - Products to classify

HOW TO EDIT PROMPTS
-------------------
1. Open prompts/classification_prompts.json
2. Edit the "content" field in user_template
3. Update "version" number (e.g., 1.0.0 -> 1.0.1)
4. Update "last_modified" date
5. Save the file
6. Test your changes: python test_prompt_changes.py
7. If tests pass, run on real data

EXAMPLE MODIFICATION: Change priority categories
-------------------------------------------------
Find this section in user_template:
  "9. high_level_category: Classification level - use these rules:
     - \"PRIORITY VMS\" = Basic vitamins, minerals, multivitamins, omega-3, probiotics
     - \"NON-PRIORITY VMS\" = All other supplements (sports, herbs, specialty)"

Change to:
  "9. high_level_category: Classification level - use these rules:
     - \"PRIORITY VMS\" = Basic vitamins, minerals, multivitamins
     - \"STRATEGIC VMS\" = Omega-3, probiotics, CoQ10
     - \"NON-PRIORITY VMS\" = All other supplements"

TESTING PROMPTS
---------------
Command: python test_prompt_changes.py

This will:
  - Test all few-shot examples
  - Show match rates
  - Highlight mismatches
  - Validate JSON syntax

ADDING FEW-SHOT EXAMPLES
-------------------------
Add to "few_shot_examples" array:
{
  "description": "Example: Probiotic supplement",
  "input": {
    "brand": "garden of life",
    "title": "raw probiotics ultimate care 100 billion 30 capsules"
  },
  "expected_output": {
    "ingredient": "Probiotics",
    "category": "DIGESTIVE HEALTH",
    "subcategory": "PROBIOTICS",
    "form": "Capsule",
    ...
  }
}


================================================================================
5. FILTERING PATTERNS
================================================================================

PURPOSE
-------
Remove non-supplements BEFORE sending to expensive LLM API.
Two-stage filtering:
  Stage 1: Amazon subcategory lookup (570+ known categories)
  Stage 2: Title keyword filtering (70 keywords with auto-variations)

FILTERING SAVES MONEY
----------------------
- R system removed 26,412 non-supplements from 31,446 products (84%)
- Our system removes 25,673 products (82%)
- Title keywords alone catch 390+ products per run
- Estimated savings: ~$2/run, ~$100/year in LLM costs

================================================================================
STAGE 1: AMAZON SUBCATEGORY FILTERING
================================================================================

FILE: reference_data/amazon_subcategory_lookup.csv
FORMAT: CSV (Excel-editable)

COLUMNS:
  subcategory,action,category,subcategory_remap

ACTIONS:
  - REMOVE: Not a supplement (books, clothing, equipment)
  - REMAP: Is a supplement, map to our category

EXAMPLE ENTRIES:
  books,REMOVE,,,
  vitamins & supplements,REMAP,BASIC VITAMINS & MINERALS,,
  sports nutrition,REMAP,ACTIVE NUTRITION,,

HOW IT WORKS:
  1. System checks product's Amazon subcategory
  2. If REMOVE → Product filtered out immediately
  3. If REMAP → Product kept for classification
  4. If UNKNOWN → Product kept + logged for review

TO UPDATE:
  1. Download from S3: amazon_subcategory_lookup.csv
  2. Add new row: subcategory_name,REMOVE or REMAP,,,
  3. Upload back to S3
  4. Next run will use updated file

HANDLING UNKNOWNS:
  After each run, check: audit/[file_id]/run_X/unknown_subcategories.csv
  Shows ALL products with unknown subcategories
  Review and add to main lookup file

================================================================================
STAGE 2: TITLE KEYWORD FILTERING
================================================================================

FILE: reference_data/non_supplement_keywords.csv
FORMAT: CSV (Excel-editable)
KEYWORDS: 70 (across 10 categories)

PURPOSE:
  Catches non-supplements that passed subcategory filtering
  Automates manual cleanup that was done after R code classification

CSV STRUCTURE:
  keyword,category,auto_variations,exceptions,notes

COLUMN DETAILS:

1. keyword (REQUIRED)
   - Word or phrase to search for in product title
   - Examples: "book", "treadmill", "face mask", "test kit"
   - Case-insensitive

2. category (OPTIONAL)
   - Your organizational grouping
   - Examples: books_media, exercise_equipment, cosmetics
   - Does NOT affect filtering

3. auto_variations (REQUIRED: "yes" or "no")
   - Controls automatic generation of variations
   
   If "yes":
     "book" generates → book, books, ebook, e-book, bookguide
     "test kit" generates → testkit, test-kit, testkits, rapidtestkit
   
   If "no":
     Only searches for exact keyword
   
   USE "yes" FOR: Most keywords (handles messy titles)
   USE "no" FOR: Already plural (jewelry), very specific (cpap)

4. exceptions (OPTIONAL)
   - Comma-separated words that SAVE the product
   - If title contains keyword AND exception → Product KEPT
   
   Example: "supplement,capsule,softgel"
   
   USE FOR: Ambiguous keywords
     - "cream" could be face cream (remove) OR protein ice cream flavor (keep)
     - "gel" could be hair gel (remove) OR softgel supplement (keep)

5. notes (OPTIONAL)
   - Your internal comments
   - Does NOT affect filtering

CURRENT CATEGORIES (70 keywords):
  - Books & Media: book, dvd
  - Exercise Equipment: treadmill, trampoline, resistance band, yoga mat, etc.
  - Pet Products: dog cone, flea, tick, pet vest
  - Cosmetics: serum, cream, moisturizer, toner, balm, gel, scrub
  - Medical Devices: snoring device, cpap, thermometer
  - Apparel: underwear, vest, pants, shorts, jacket
  - Food: syrup, candy, cookie, snack bar
  - Household: tattoo, patch, diaper, wipe
  - Jewelry: jewelry, gemstone, key chain
  - Body Care: body wash, facial mask, shampoo, perfume, lotion

WORD BOUNDARY PROTECTION:
  - Short words (≤4 chars) use word boundaries
  - "gel" WON'T match "gelsemium" (homeopathic name)
  - "vest" WON'T match "harvest" (food product)
  - Long words use substring matching
  - "gemstone" WILL match "healinggemstone" (catches messy titles)

================================================================================
HOW TO ADD NEW KEYWORDS
================================================================================

EXAMPLE 1: Simple Keyword (No Exceptions)

SCENARIO: "blender" products are getting through

STEPS:
1. Open: reference_data/non_supplement_keywords.csv
2. Add row at bottom:
   blender,equipment,yes,,Kitchen blenders not supplements

3. Save and upload to S3
4. Next run will remove "blender" products

RESULT:
  ✗ REMOVES: "NutriBullet High-Speed Blender 1200W"
  ✗ REMOVES: "Vitamix Professional Series 750 Blender"
  ✗ REMOVES: "Magic Bullet Blender Small"

EXAMPLE 2: Keyword with Exceptions

SCENARIO: "powder" products need filtering, but many supplements are powders

ANALYSIS:
  - "powder" could be makeup powder (remove)
  - "powder" could be protein powder (keep)
  - "powder" could be preworkout powder (keep)

SOLUTION: Add exceptions

ROW TO ADD:
  powder,cosmetics,yes,"protein,supplement,creatine,collagen",Keep if supplement powder

RESULTS:
  ✗ REMOVES: "MAC Studio Fix Powder Foundation"
  ✗ REMOVES: "Setting Powder Translucent Loose Face Powder"
  ✓ KEEPS: "Optimum Nutrition Gold Standard Whey Protein Powder"
  ✓ KEEPS: "Creatine Monohydrate Powder 5000mg"
  ✓ KEEPS: "Collagen Peptides Powder Unflavored"

EXAMPLE 3: Multi-Word Phrase

SCENARIO: "yoga mat" products need removal

ROW TO ADD:
  yoga mat,exercise_equipment,yes,,Fitness equipment

SYSTEM AUTO-GENERATES:
  yoga mat, yoga mats, yogamat, yogamats, yoga-mat, yoga-mats

RESULTS:
  ✗ REMOVES: "Yoga Mat Extra Thick Non-Slip"
  ✗ REMOVES: "PremiumYogaMat with Carrying Strap"
  ✗ REMOVES: "Yoga-Mat TPE Eco-Friendly"

================================================================================
HOW TO REVIEW KEYWORDS (AFTER EACH RUN)
================================================================================

AUDIT FILE 1: removed_by_title_keyword.csv
LOCATION: s3://.../audit/[file_id]/run_X/step1_subcategory_filtering/

SHOWS:
  - Which products were removed by title keywords
  - Which specific keyword triggered removal
  
EXAMPLE ROWS:
  asin,brand,title,amazon_subcategory,reasoning
  B123,Nike,Premium Yoga Mat,fitness,Title keyword filter: 'yoga mat'
  B456,Olay,Anti-Aging Face Cream,vitamins,Title keyword filter: 'cream'

USE THIS TO:
  ✓ Verify keywords catching correct products
  ✓ Find false positives (supplements wrongly removed)
  ✓ Identify patterns for new keywords

AUDIT FILE 2: removed_by_subcategory.csv
LOCATION: Same folder

SHOWS:
  - Products removed by Amazon subcategory lookup
  
EXAMPLE ROWS:
  asin,brand,title,amazon_subcategory,reasoning
  B789,Publisher,Vitamin Book,books,Subcategory filter: 'books'

LOG FILE: step1_subcategory_filtering.log
SHOWS STATISTICS:
  Input: 31,446 products
  Removed by subcategory: 25,283 (98%)
  Removed by title keyword: 390 (2%)
  Total removed: 25,673
  Passed forward: 5,773

================================================================================
TROUBLESHOOTING KEYWORDS
================================================================================

PROBLEM 1: Too Many Supplements Removed

SYMPTOM: Legitimate supplements in removed_by_title_keyword.csv

EXAMPLE: "Omega-3 Fish Oil Softgel" removed by "gel" keyword

SOLUTION: Add exception
  BEFORE: gel,cosmetics,yes,"softgel,capsule",Keep supplement forms
  AFTER: gel,cosmetics,yes,"softgel,capsule,omega",Keep supplement forms

PROBLEM 2: Non-Supplements Getting Through

SYMPTOM: Few removals in removed_by_title_keyword.csv, but you see non-supplements

EXAMPLE: "Resistance Band Set" not being caught

SOLUTION: Add new keyword
  resistance band,exercise_equipment,yes,,Workout bands

PROBLEM 3: False Positives from Substring Matching

SYMPTOM: Words like "harvest" being removed by "vest"

CAUSE: Substring matching too aggressive

SOLUTION: Already handled automatically!
  - Short words (≤4 chars) use word boundaries
  - "vest" matches " vest " but not "harvest"

PROBLEM 4: Variations Not Working

SYMPTOM: "ebook" not caught even though "book" keyword exists

CHECK: Is auto_variations = "yes"?
  If "no" → Change to "yes"
  If "yes" → Verify the product title actually contains variation

================================================================================
TESTING KEYWORDS LOCALLY
================================================================================

BEFORE deploying to S3, test your changes:

COMMAND:
  python test_keyword_variations.py

THIS WILL:
  - Load your non_supplement_keywords.csv
  - Test on sample product titles
  - Show what gets removed and why
  - Verify exceptions work correctly

SAMPLE OUTPUT:
  Testing: "Vitamin C Face Serum"
    ✗ REMOVED by keyword: 'serum'
  
  Testing: "Immune Support Serum Supplement"
    ✓ KEPT (exception: 'supplement')
  
  Testing: "Premium Yoga Mat"
    ✗ REMOVED by keyword: 'yoga mat'

================================================================================
BEST PRACTICES
================================================================================

1. START CONSERVATIVE
   - Add keywords gradually
   - Test on small dataset first
   - Review audit files after each change

2. USE EXCEPTIONS WISELY
   - Only for truly ambiguous terms
   - Be specific: "supplement,oral" not just "supplement"
   - Test thoroughly

3. ORGANIZE BY CATEGORY
   - Use category column for grouping
   - Makes maintenance easier
   - Examples: cosmetics, pet_products, exercise_equipment

4. DOCUMENT YOUR CHANGES
   - Use notes column
   - Explain why keyword was added
   - Helps future maintenance

5. REVIEW REGULARLY
   - Check audit files after each run
   - Look for patterns
   - Refine keywords as needed

6. MEASURE IMPACT
   - Track before/after removal counts
   - Monitor false positives
   - Adjust if needed

================================================================================
--------
reference_data/non_supplement_patterns.json

FILE STRUCTURE
--------------
{
  "patterns": {
    "books_and_media": {
      "description": "Books, guides, manuals",
      "keywords": ["\\bbook\\b", "\\bguide\\b"],
      "exceptions": []
    },
    "topical_and_body_care": {
      "keywords": ["\\bserum\\b", "\\boil\\b"],
      "exceptions": [
        {
          "keyword": "\\bserum\\b",
          "allow_if_contains": ["supplement", "capsule"],
          "description": "Serum can be supplement ingredient name"
        }
      ]
    }
  }
}

PATTERN CATEGORIES
------------------
1. books_and_media: book, cookbook, guide, manual, handbook, dvd, journal
2. equipment_and_devices: equipment, machine, device, scale, mat, massager
3. medical_devices: test kit, thermometer, stethoscope, bandage
4. topical_and_body_care: lotion, cream, serum*, oil*, shampoo, wash
5. food_and_beverages: snack, bar*, cookie, candy, juice, coffee
6. apparel_and_accessories: t-shirt, gloves, socks, hat, bag

*With smart exceptions (see EXCEPTION LOGIC below)

WORD BOUNDARIES
---------------
ALWAYS use \\b for exact word matching:

GOOD:
  "\\bbook\\b"   → matches "book" but not "booking" or "facebook"
  "\\bmat\\b"    → matches "mat" but not "format" or "automatic"

BAD:
  "book"         → matches "booking", "facebook", "booklet"
  "mat"          → matches "format", "automatic", "math"

ADDING NEW KEYWORDS
-------------------
1. Open reference_data/non_supplement_patterns.json
2. Find the appropriate category
3. Add to "keywords" array with \\b:
   "keywords": [
     "\\bbook\\b",
     "\\bdvd\\b"    ← NEW
   ]
4. Save file
5. Test: python test_filtering_patterns.py

EXCEPTION LOGIC
---------------
Some words are ambiguous:
  - "serum" = topical product OR supplement ingredient
  - "oil" = body oil OR fish oil supplement
  - "bar" = protein bar supplement OR candy bar

HOW EXCEPTIONS WORK:
1. If title contains "serum" → normally REMOVED
2. BUT if title ALSO contains "supplement" → KEPT (it's a supplement)

EXAMPLE:
  "Hair Growth Serum"                  → REMOVED (topical)
  "Vitamin C Serum Supplement Capsules" → KEPT (supplement)

ADDING EXCEPTION
----------------
{
  "keyword": "\\bcream\\b",
  "allow_if_contains": [
    "supplement",
    "capsule",
    "powder"
  ],
  "description": "Cream can be in supplement names"
}

CREATING NEW CATEGORY
----------------------
{
  "pet_products": {
    "description": "Pet supplements and products",
    "keywords": [
      "\\bdog\\b",
      "\\bcat\\b",
      "\\bpet\\b"
    ],
    "exceptions": []
  }
}

TESTING PATTERNS
----------------
Command: python test_filtering_patterns.py

Output shows:
  - Total products tested
  - How many removed vs passed
  - Reason for each removal
  - Expected vs actual results
  - Pass/fail for each test case

REMOVED PRODUCT OUTPUT
----------------------
Products filtered out get:
  category: "REMOVE"
  subcategory: "REMOVE"
  high_level_category: "REMOVE"
  reasoning: "Title contains non-supplement keyword: book"
  confidence: "high"

COST SAVINGS
------------
Without filtering: ~15,000 non-supplements × $0.0003 = $4.50 wasted
With filtering: $0 (filtered before LLM)
Time saved: ~4 hours per run


================================================================================
6. REFERENCE DATA
================================================================================

All reference data is stored as JSON files in reference_data/

AMAZON SUBCATEGORY LOOKUP
--------------------------
File: amazon_subcategory_lookup.json
Purpose: Maps Amazon subcategories to actions (REMOVE or REMAP)
Entries: 409 known subcategories

Structure:
{
  "acne & blemish treatments": {
    "action": "REMOVE",
    "category": null,
    "subcategory": null
  },
  "vitamin supplements": {
    "action": "REMAP",
    "category": "BASIC VITAMINS & MINERALS",
    "subcategory": "LETTER VITAMINS"
  }
}

INGREDIENT CATEGORY LOOKUP
---------------------------
File: ingredient_category_lookup.json
Purpose: Keyword matching for fast, free classification
Entries: ~500 ingredient patterns

Structure:
{
  "vitamin d": {
    "ingredient": "Vitamin D",
    "category": "BASIC VITAMINS & MINERALS",
    "subcategory": "LETTER VITAMINS"
  }
}

VALID CATEGORIES
----------------
File: valid_categories.json
Purpose: All valid category/subcategory combinations for validation

Structure:
{
  "BASIC VITAMINS & MINERALS": [
    "LETTER VITAMINS",
    "MINERALS",
    "COMBINED MULTIVITAMINS"
  ]
}

VALID ATTRIBUTES
----------------
File: valid_attributes.json
Purpose: All valid forms, age groups, genders, health focuses

Structure:
{
  "forms": ["Capsule", "Tablet", "Softgel", "Powder", ...],
  "age_groups": ["AGE GROUP - ADULT", "AGE GROUP - CHILD", ...],
  "genders": ["GENDER - NON SPECIFIC", "GENDER - MALE", ...],
  "health_focuses": ["BONE HEALTH", "HEART HEALTH", ...]
}

HEALTH FOCUS LOOKUP
-------------------
File: ingredient_health_focus_lookup.json
Purpose: Fallback health focus by ingredient
Entries: ~200 ingredient-to-health-focus mappings

Structure:
{
  "VITAMIN D": "BONE HEALTH",
  "OMEGA-3": "HEART HEALTH"
}

NON-SUPPLEMENT PATTERNS
-----------------------
File: non_supplement_patterns.json
Purpose: Title-based filtering patterns
See section 5 (FILTERING PATTERNS) for details


================================================================================
7. TESTING
================================================================================

TEST SCRIPTS
------------
1. test_detailed_output.py    - Test 5 products with full output details
2. test_quick_load.py          - Test 10 products for quick validation
3. test_full_load.py           - Test 100 products with cost projection
4. test_parallel_processing.py - Test parallel LLM calls (5x speedup)
5. test_filtering_patterns.py  - Validate filtering pattern changes
6. test_prompt_changes.py      - Validate prompt modifications

RUNNING TESTS
-------------
# Detailed output (5 products)
python test_detailed_output.py

# Quick load (10 products)
python test_quick_load.py

# Test filtering
python test_filtering_patterns.py

# Test prompts
python test_prompt_changes.py

EXPECTED OUTPUT
---------------
Each test shows:
  - Number of products processed
  - Classification results
  - Reasoning for each decision
  - Confidence scores
  - Cost estimates (for LLM tests)
  - Pass/fail status

INTERPRETING RESULTS
--------------------
✓ All fields present: ingredient, category, subcategory, form, age, gender, 
                       health_focus, organic, high_level_category, count, 
                       size, unit_of_measurement, reasoning, confidence

✓ Removed products: category=REMOVE, subcategory=REMOVE, 
                    high_level_category=REMOVE

✓ Confidence levels: high (90%+ of cases), medium, low

PERFORMANCE BENCHMARKS
----------------------
Sequential processing: ~5 seconds per product (gpt-5-mini)
Parallel processing: ~1 second per product (5 workers)
Full dataset (3,274 products): ~22 minutes with parallel processing


================================================================================
8. TROUBLESHOOTING
================================================================================

PROBLEM: LLM RETURNING WRONG CATEGORIES
Solution 1: Check reference_data/valid_categories.json for exact category names
Solution 2: Update few-shot examples in prompts/classification_prompts.json
Solution 3: Make prompt instructions more explicit

PROBLEM: TOO MANY FALSE POSITIVES (supplements being removed)
Solution 1: Add exceptions in reference_data/non_supplement_patterns.json
Solution 2: Use more specific word boundaries (\\bword\\b)
Solution 3: Review reasoning field to understand why removed

PROBLEM: NOT ENOUGH REMOVALS (non-supplements passing through)
Solution 1: Add more keywords to reference_data/non_supplement_patterns.json
Solution 2: Check Amazon subcategory lookup for missing categories
Solution 3: Run test_filtering_patterns.py to validate

PROBLEM: JSON PARSING ERRORS
Solution 1: Validate JSON syntax at jsonlint.com
Solution 2: Check for unescaped quotes in content
Solution 3: Ensure proper bracket matching

PROBLEM: LOW CONFIDENCE SCORES
Solution 1: Add more specific rules in prompt
Solution 2: Include more few-shot examples
Solution 3: Check if reference data is complete

PROBLEM: SLOW PROCESSING
Solution 1: Use parallel processing (test_parallel_processing.py)
Solution 2: Increase batch size in LLM classifier
Solution 3: Filter more aggressively to reduce LLM calls

PROBLEM: HIGH COSTS
Solution 1: Improve filtering to remove more non-supplements early
Solution 2: Use keyword matching instead of LLM when possible
Solution 3: Switch to gpt-4o-mini for lower costs

PROBLEM: PATTERN NOT WORKING
Check 1: Word boundaries - use \\b not \b
Check 2: Regex escaping - special characters need \\
Check 3: Case sensitivity - all matching is lowercase
Check 4: Test with test_filtering_patterns.py


================================================================================
9. COMMON MODIFICATIONS
================================================================================

MODIFY CLASSIFICATION RULES
----------------------------
File: prompts/classification_prompts.json
Change: Edit "user_template" content
Test: python test_prompt_changes.py

EXAMPLE: Add new field
{
  "content": "...existing rules...\n12. new_field: Description and rules"
}

ADD NEW FILTERING KEYWORDS
---------------------------
File: reference_data/non_supplement_patterns.json
Change: Add to appropriate category's "keywords" array
Test: python test_filtering_patterns.py

EXAMPLE:
"books_and_media": {
  "keywords": ["\\bbook\\b", "\\bmagazine\\b"]  ← ADD NEW
}

ADD EXCEPTION FOR AMBIGUOUS WORD
---------------------------------
File: reference_data/non_supplement_patterns.json
Change: Add to category's "exceptions" array
Test: python test_filtering_patterns.py

EXAMPLE:
"exceptions": [
  {
    "keyword": "\\bcream\\b",
    "allow_if_contains": ["supplement", "capsule"],
    "description": "Cream in supplement names"
  }
]

ADD NEW SUBCATEGORY ACTION
---------------------------
File: reference_data/amazon_subcategory_lookup.json
Change: Add new entry
Test: Process sample file

EXAMPLE:
{
  "new_subcategory_name": {
    "action": "REMOVE",
    "category": null,
    "subcategory": null
  }
}

MODIFY PRIORITY LEVELS
-----------------------
File: prompts/classification_prompts.json
Change: Edit rule #9 in user_template
Test: python test_prompt_changes.py

ADD VALID CATEGORY
------------------
File: reference_data/valid_categories.json
Change: Add new category with subcategories
Test: python test_detailed_output.py

EXAMPLE:
{
  "NEW CATEGORY": [
    "SUBCATEGORY 1",
    "SUBCATEGORY 2"
  ]
}


================================================================================
10. SUPPORT
================================================================================

GETTING HELP
------------
1. Read this documentation (COMPLETE_DOCUMENTATION.txt)
2. Run relevant test scripts to diagnose issues
3. Check reference data files for missing entries
4. Review prompt configurations for clarity
5. Contact technical support with specific error messages

BEST PRACTICES
--------------
1. ALWAYS test changes before production
2. Keep version numbers updated
3. Document modifications
4. Use word boundaries in patterns
5. Validate JSON syntax
6. Review test results carefully
7. Monitor costs and performance
8. Keep reference data up to date

MAINTENANCE SCHEDULE
--------------------
Weekly:
  - Review unknown subcategories in logs
  - Check for new non-supplement patterns
  - Monitor classification accuracy

Monthly:
  - Update reference data as needed
  - Review and optimize prompts
  - Test with new product samples
  - Verify cost and performance metrics

Quarterly:
  - Full system audit
  - Update documentation
  - Train team on new features
  - Review and archive logs

REPORTING ISSUES
----------------
When reporting issues, include:
  1. Error message (exact text)
  2. Input file sample (5-10 products)
  3. Expected vs actual output
  4. Steps to reproduce
  5. Environment details (local or AWS)
  6. Test script results
  7. Log files if available

CONTACT INFORMATION
-------------------
Technical Support: [Add contact info]
Documentation Updates: [Add contact info]
Emergency Contact: [Add contact info]


================================================================================
END OF DOCUMENTATION
================================================================================

Last Updated: 2025-01-24
Version: 1.0.0
System: Bedrock POC - Product Classification
Status: Production Ready

